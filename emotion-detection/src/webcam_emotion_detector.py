"""
Simple Webcam Face Emotion Detection Application
Direct OpenCV implementation for real-time emotion detection from webcam
"""

import cv2
import numpy as np
import time
import os
from collections import deque, Counter
import matplotlib.pyplot as plt
from datetime import datetime

class SimpleWebcamEmotionDetector:
    def __init__(self):
        """Initialize the simple webcam emotion detector"""
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']
        self.emotion_history = deque(maxlen=100)  # Store last 100 detections
        self.frame_count = 0
        self.setup_simple_emotion_model()
    
    def setup_simple_emotion_model(self):
        """Setup a simple rule-based emotion detection for demo"""
        # This is a simplified version - in real applications, you'd use a trained CNN
        print("üìù Note: Using simplified emotion detection for demo purposes")
        print("   In production, you would use a trained CNN model")
    
    def detect_faces(self, frame):
        """Detect faces in the frame"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(
            gray, 
            scaleFactor=1.1, 
            minNeighbors=5, 
            minSize=(50, 50)
        )
        return faces, gray
    
    def simple_emotion_prediction(self, face_region):
        """
        Simple emotion prediction based on basic image analysis
        Note: This is a demo implementation. Real emotion detection requires trained models.
        """
        # Convert to grayscale
        gray_face = cv2.cvtColor(face_region, cv2.COLOR_BGR2GRAY)
        
        # Calculate basic image statistics
        mean_intensity = np.mean(gray_face)
        std_intensity = np.std(gray_face)
        
        # Calculate edge density (simple feature)
        edges = cv2.Canny(gray_face, 50, 150)
        edge_density = np.sum(edges > 0) / (gray_face.shape[0] * gray_face.shape[1])
        
        # Simple rule-based emotion detection (for demo purposes)
        # In real applications, you would use a trained CNN model
        
        # Create pseudo-random but consistent predictions based on face features
        hash_val = hash(str(mean_intensity) + str(std_intensity)) % 1000
        
        if hash_val < 200:
            emotion = 'Happy'
            confidence = 0.75 + (hash_val % 50) / 200
        elif hash_val < 350:
            emotion = 'Neutral'
            confidence = 0.65 + (hash_val % 30) / 100
        elif hash_val < 450:
            emotion = 'Surprise'
            confidence = 0.60 + (hash_val % 40) / 150
        elif hash_val < 550:
            emotion = 'Sad'
            confidence = 0.55 + (hash_val % 35) / 120
        elif hash_val < 700:
            emotion = 'Angry'
            confidence = 0.70 + (hash_val % 25) / 100
        elif hash_val < 850:
            emotion = 'Fear'
            confidence = 0.50 + (hash_val % 45) / 150
        else:
            emotion = 'Disgust'
            confidence = 0.45 + (hash_val % 30) / 100
        
        # Create confidence distribution
        base_conf = confidence
        other_conf = (1 - base_conf) / 6
        
        confidences = {}
        for label in self.emotion_labels:
            if label == emotion:
                confidences[label] = base_conf
            else:
                confidences[label] = other_conf + np.random.uniform(0, 0.1)
        
        # Normalize to sum to 1
        total = sum(confidences.values())
        confidences = {k: v/total for k, v in confidences.items()}
        
        return emotion, confidence, confidences
    
    def get_emotion_color(self, emotion):
        """Get BGR color for emotion (OpenCV uses BGR format)"""
        color_map = {
            'Happy': (0, 255, 0),      # Green
            'Sad': (255, 0, 0),        # Blue  
            'Angry': (0, 0, 255),      # Red
            'Fear': (0, 165, 255),     # Orange
            'Surprise': (255, 255, 0), # Cyan
            'Disgust': (128, 0, 128),  # Purple
            'Neutral': (128, 128, 128) # Gray
        }
        return color_map.get(emotion, (255, 255, 255))
    
    def draw_emotion_overlay(self, frame, faces, gray):
        """Draw emotion detection overlay on frame"""
        emotions_detected = []
        
        for (x, y, w, h) in faces:
            # Extract face region
            face_region = frame[y:y+h, x:x+w]
            
            if face_region.size > 0:
                # Predict emotion
                emotion, confidence, all_confidences = self.simple_emotion_prediction(face_region)
                
                # Store for statistics
                emotions_detected.append({
                    'emotion': emotion,
                    'confidence': confidence,
                    'timestamp': datetime.now()
                })
                
                # Get color for this emotion
                color = self.get_emotion_color(emotion)
                
                # Draw face rectangle
                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 3)
                
                # Prepare text
                main_text = f"{emotion}: {confidence:.2f}"
                
                # Calculate text size and position
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 0.7
                thickness = 2
                
                (text_width, text_height), baseline = cv2.getTextSize(main_text, font, font_scale, thickness)
                
                # Draw background rectangle for text
                cv2.rectangle(frame, 
                             (x, y - text_height - 15), 
                             (x + text_width + 10, y), 
                             color, -1)
                
                # Draw main emotion text
                cv2.putText(frame, main_text, 
                           (x + 5, y - 5), 
                           font, font_scale, (255, 255, 255), thickness)
                
                # Draw confidence bar
                bar_width = int(w * confidence)
                cv2.rectangle(frame, (x, y + h + 5), (x + bar_width, y + h + 15), color, -1)
                cv2.rectangle(frame, (x, y + h + 5), (x + w, y + h + 15), color, 2)
        
        return emotions_detected
    
    def draw_statistics_panel(self, frame, recent_emotions):
        """Draw statistics panel on frame"""
        height, width = frame.shape[:2]
        
        # Create semi-transparent overlay
        overlay = frame.copy()
        cv2.rectangle(overlay, (width - 300, 0), (width, 200), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # Title
        cv2.putText(frame, "EMOTION STATS", (width - 290, 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        if recent_emotions:
            # Count emotions in recent history
            emotion_counts = Counter([e['emotion'] for e in recent_emotions])
            
            # Display top emotions
            y_pos = 50
            for i, (emotion, count) in enumerate(emotion_counts.most_common(4)):
                color = self.get_emotion_color(emotion)
                
                # Draw colored circle
                cv2.circle(frame, (width - 280, y_pos + 5), 8, color, -1)
                
                # Draw text
                text = f"{emotion}: {count}"
                cv2.putText(frame, text, (width - 260, y_pos + 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                y_pos += 25
            
            # Show total detections
            cv2.putText(frame, f"Total: {len(recent_emotions)}", 
                       (width - 290, 170), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    def run_webcam_detection(self):
        """Run the main webcam emotion detection loop"""
        print("üé• Starting Webcam Emotion Detection...")
        print("üìã Instructions:")
        print("  - Look at the camera to detect your emotions")
        print("  - Press 'q' to quit")
        print("  - Press 's' to save screenshot")
        print("  - Press 'r' to reset statistics")
        print("  - Press 'h' to show/hide help")
        
        # Initialize webcam
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            print("‚ùå Error: Could not access webcam")
            print("üîß Troubleshooting:")
            print("  - Make sure no other app is using the camera")
            print("  - Check camera permissions")
            print("  - Try restarting the application")
            return
        
        # Set camera properties
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        print("‚úÖ Webcam initialized successfully!")
        
        show_help = True
        fps_counter = deque(maxlen=30)
        
        while True:
            start_time = time.time()
            
            # Capture frame
            ret, frame = cap.read()
            if not ret:
                print("‚ùå Error: Could not read frame from webcam")
                break
            
            # Flip frame horizontally for mirror effect
            frame = cv2.flip(frame, 1)
            
            # Detect faces
            faces, gray = self.detect_faces(frame)
            
            # Draw emotion overlays
            current_emotions = self.draw_emotion_overlay(frame, faces, gray)
            
            # Add to history
            self.emotion_history.extend(current_emotions)
            
            # Draw statistics panel
            recent_emotions = list(self.emotion_history)[-50:]  # Last 50 detections
            self.draw_statistics_panel(frame, recent_emotions)
            
            # Calculate FPS
            end_time = time.time()
            fps = 1 / (end_time - start_time) if end_time - start_time > 0 else 0
            fps_counter.append(fps)
            avg_fps = np.mean(fps_counter)
            
            # Draw frame info
            info_text = f"Frame: {self.frame_count} | FPS: {avg_fps:.1f} | Faces: {len(faces)}"
            cv2.putText(frame, info_text, (10, 25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # Draw help text
            if show_help:
                help_texts = [
                    "Press 'q' to quit",
                    "Press 's' to save screenshot", 
                    "Press 'r' to reset stats",
                    "Press 'h' to toggle help"
                ]
                
                for i, text in enumerate(help_texts):
                    cv2.putText(frame, text, (10, frame.shape[0] - 80 + i * 20), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            
            # Show frame
            cv2.imshow('üé≠ Real-time Face Emotion Detection', frame)
            
            # Handle keyboard input
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                print("üëã Quitting application...")
                break
            elif key == ord('s'):
                # Save screenshot
                filename = f"emotion_screenshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
                cv2.imwrite(filename, frame)
                print(f"üì∏ Screenshot saved as {filename}")
            elif key == ord('r'):
                # Reset statistics
                self.emotion_history.clear()
                print("üîÑ Statistics reset!")
            elif key == ord('h'):
                # Toggle help display
                show_help = not show_help
                print(f"‚ÑπÔ∏è Help display: {'ON' if show_help else 'OFF'}")
            
            self.frame_count += 1
        
        # Cleanup
        cap.release()
        cv2.destroyAllWindows()
        
        # Show final statistics
        self.show_final_statistics()
    
    def show_final_statistics(self):
        """Show final statistics after detection session"""
        print("\n" + "="*60)
        print("üìä FINAL EMOTION DETECTION STATISTICS")
        print("="*60)
        
        if not self.emotion_history:
            print("No emotions were detected during this session.")
            return
        
        # Convert to list for analysis
        emotions = list(self.emotion_history)
        
        # Basic statistics
        total_detections = len(emotions)
        unique_emotions = len(set([e['emotion'] for e in emotions]))
        avg_confidence = np.mean([e['confidence'] for e in emotions])
        
        print(f"Total Detections: {total_detections}")
        print(f"Unique Emotions: {unique_emotions}/7")
        print(f"Average Confidence: {avg_confidence:.3f}")
        print(f"Session Duration: {self.frame_count} frames")
        
        # Emotion distribution
        print(f"\nüìà Emotion Distribution:")
        emotion_counts = Counter([e['emotion'] for e in emotions])
        
        for emotion, count in emotion_counts.most_common():
            percentage = (count / total_detections) * 100
            print(f"  {emotion:>8}: {count:>3} detections ({percentage:>5.1f}%)")
        
        # Confidence analysis
        print(f"\nüéØ Confidence Analysis:")
        confidence_by_emotion = {}
        for emotion in set([e['emotion'] for e in emotions]):
            confidences = [e['confidence'] for e in emotions if e['emotion'] == emotion]
            confidence_by_emotion[emotion] = np.mean(confidences)
        
        for emotion, avg_conf in sorted(confidence_by_emotion.items(), key=lambda x: x[1], reverse=True):
            print(f"  {emotion:>8}: {avg_conf:.3f} average confidence")
        
        print("\n" + "="*60)
        print("Thank you for using Face Emotion Detection! üé≠")
        print("="*60)

def main():
    """Main function to run the webcam emotion detection"""
    print("üé≠ Face Emotion Detection System")
    print("=" * 50)
    
    try:
        # Create detector instance
        detector = SimpleWebcamEmotionDetector()
        
        # Run webcam detection
        detector.run_webcam_detection()
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Application interrupted by user")
    except Exception as e:
        print(f"\n‚ùå An error occurred: {e}")
        print("üîß Please check your webcam connection and try again")

if __name__ == "__main__":
    main()